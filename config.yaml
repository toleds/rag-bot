llms:
  llm_type: "huggingface" # openai, huggingface, ollama (local llm server)
  temperature: 1.5
  model_name: "meta-llama/Llama-3.2-1B"
#  api_key: "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"
  api_key: "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"
  local_server: "http://localhost:11434" # for ollama local server only

vector_store:
  vector_type: "faiss"  # Options: "chroma", "faiss"
  data_path: "./db"
  resource_path: "./resource"

embeddings:
  embedding_type: "huggingface" # huggingface=HuggingFaceEmbeddings, openai=OpenAIEmbeddings, etc
  embedding_model: "sentence-transformers/all-mpnet-base-v2"
  dimension: 768 # check the embedding model dimension (not for chroma)

