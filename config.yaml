llms:
  llm_type: "ollama" # openai, huggingface, ollama (local llm server)
  temperature: 1.5
  model_name: "mistral"
  api_key: "<openai or huggingface key>"
  local_server: "http://localhost:11434" # for ollama local server only

vector_store:
  vector_type: "faiss"  # Options: "chroma", "faiss"
  data_path: "./db"
  resource_path: "./resource"

embeddings:
  embedding_type: "huggingface" # huggingface=HuggingFaceEmbeddings, openai=OpenAIEmbeddings, etc
  embedding_model: "sentence-transformers/all-mpnet-base-v2"
  dimension: 768 # check the embedding model dimension (not for chroma)

